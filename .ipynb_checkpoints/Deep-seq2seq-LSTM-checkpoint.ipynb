{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-02T19:01:11.373246",
     "start_time": "2017-05-02T12:01:03.248376-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import legacy_seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Joint Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-02T21:46:13.737255",
     "start_time": "2017-05-02T14:46:11.593890-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = 'labels/'\n",
    "frames = []\n",
    "for filename in os.listdir(directory):\n",
    "    annotations = loadmat(directory + filename)\n",
    "    if annotations['action'][0] == 'squat':\n",
    "        # Create Nx13x2 joint labels for each video\n",
    "        frames.append(np.stack([annotations['x'], annotations['y']], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep only videos with more than 70 image frames\n",
    "top_frames = []\n",
    "for i in range(231):\n",
    "    if frames[i].shape[0] > 70:\n",
    "        top_frames.append(frames[i])\n",
    "\n",
    "\n",
    "frames_train = top_frames[:150]\n",
    "frames_test = top_frames[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(top_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-02T22:07:31.218304",
     "start_time": "2017-05-02T15:07:31.211298-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = 13 # num of joints\n",
    "k = 50 # training num\n",
    "T = 10 # prediction num\n",
    "H = 1024 # hidden layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-02T22:07:51.273682",
     "start_time": "2017-05-02T15:07:51.249663-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(p, weights, biases):\n",
    "    # p should be shape (batch_size, T, 2 * L)\n",
    "    # unstack gets us a list of T (batch_size, 2 * L) tensors\n",
    "    stacked_lstm = rnn.MultiRNNCell([rnn.BasicLSTMCell(H, forget_bias=1.0) for _ in range(2)])\n",
    "    batch_size = tf.shape(p)[0]\n",
    "    p = tf.unstack(p, k, axis=1)\n",
    "    outputs, states = legacy_seq2seq.basic_rnn_seq2seq(p,  [p[-1]]*T, stacked_lstm)\n",
    "    \n",
    "    # outputs is a list of T (batch_size, H) arrays\n",
    "    # concat outputs is (batch_size * T, H)\n",
    "    concat_outputs = tf.concat(outputs, axis=0)\n",
    "    \n",
    "    # predictions is (batch_size * T, 2 * L)\n",
    "    predictions = tf.matmul(concat_outputs, weights) + biases\n",
    "    \n",
    "    # reshape into (T, batch_size, 2 * L) then transpose into (batch_size, T, 2 * L)\n",
    "    return tf.transpose(tf.reshape(predictions, (T, batch_size, L * 2)), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-02T22:17:11.426069",
     "start_time": "2017-05-02T15:17:06.520790-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 2000\n",
    "batch_size = 10\n",
    "n_videos = len(frames_train)\n",
    "display_step = 50\n",
    "\n",
    "p_input = tf.placeholder(tf.float32, shape=[None, k, L*2])\n",
    "p_output = tf.placeholder(tf.float32, shape=[p_input.get_shape()[0], T, L*2])\n",
    "\n",
    "W = tf.get_variable('W', shape=[H, L*2], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.get_variable('b', shape=[L*2], dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "p_output_predicted = RNN(p_input, W, b)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.squared_difference(p_output_predicted, p_output))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Training/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-02T22:17:29.881200",
     "start_time": "2017-05-02T15:17:22.809978-07:00"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess, 'lstm-reg-20000')\n",
    "mean_losses = []\n",
    "for epoch in range(epochs):\n",
    "    total_iter = n_videos // batch_size\n",
    "    total_iter = 1\n",
    "    total_loss = 0\n",
    "    for i in range(total_iter):\n",
    "        inputs = []\n",
    "        expected_outputs = []\n",
    "        for frame in frames_train:\n",
    "            start_time =  np.random.randint(frame.shape[0] - (k + T) + 1)\n",
    "            inputs.append(frame[start_time : start_time + k].reshape(k, 2 * L))\n",
    "            expected_outputs.append(frame[start_time + k : start_time + k + T].reshape(T, 2 * L))\n",
    "        _, loss_value = sess.run((optimizer, loss), feed_dict={ p_input : np.asarray(inputs), p_output : np.asarray(expected_outputs) })\n",
    "        total_loss += loss_value\n",
    "    mean_loss = total_loss / total_iter\n",
    "    mean_losses.append(mean_loss)\n",
    "    if (epoch + 1) % display_step == 0:\n",
    "        print('epoch %s: loss=%.4f' % (epoch + 1, mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "expected_outputs = []\n",
    "for frame in frames_train:\n",
    "    start_time =  np.random.randint(frame.shape[0] - (k + T) + 1)\n",
    "    inputs.append(frame[start_time : start_time + k].reshape(k, 2 * L))\n",
    "    expected_outputs.append(frame[start_time + k : start_time + k + T].reshape(T, 2 * L))\n",
    "\n",
    "output = sess.run((p_output_predicted), feed_dict={ p_input : np.asarray(inputs)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(T):\n",
    "    print(np.mean(np.linalg.norm(\n",
    "        output.reshape((1, T, 13, 2))[:,i,:,:] - np.array(expected_outputs).reshape((1, T, 13, 2))[:,i,:,:],\n",
    "        axis=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(T):\n",
    "    if i % 1 == 0:\n",
    "        image = i\n",
    "        print('T = ', i)\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(np.zeros((1,1)), cmap = 'gray')\n",
    "        plt.scatter((output[0][image].reshape(13,2)).T[0], (output[0][image].reshape(13,2)).T[1])\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(np.zeros((1,1)), cmap = 'gray')\n",
    "        plt.scatter((expected_outputs[0][image].reshape(13,2)).T[0], (expected_outputs[0][image].reshape(13,2)).T[1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(T):\n",
    "    if i % 1 == 0:\n",
    "        image = i\n",
    "        print('T = ', i)\n",
    "        print((output[0][image].reshape(13,2)).T[0], (output[0][image].reshape(13,2)).T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'lstm-reg', global_step=20000)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
